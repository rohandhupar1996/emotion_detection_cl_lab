{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dba1304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5341 entries, 0 to 5340\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Emotion Label  5340 non-null   object\n",
      " 1   Text           5334 non-null   object\n",
      " 2   Unnamed: 2     7 non-null      object\n",
      " 3   Unnamed: 3     5 non-null      object\n",
      " 4   Unnamed: 4     2 non-null      object\n",
      " 5   Unnamed: 5     1 non-null      object\n",
      " 6   Unnamed: 6     1 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 292.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   Emotion Label                                               Text Unnamed: 2  \\\n",
       " 0           joy  When I understood that I was admitted to the U...        NaN   \n",
       " 1          fear  I broke a window of a neighbouring house and I...        NaN   \n",
       " 2           joy                         Got a big fish in fishing.        NaN   \n",
       " 3          fear  Whenever I am alone in a dark room, walk alone...        NaN   \n",
       " 4         shame  I bought a possible answer to a homework probl...        NaN   \n",
       " \n",
       "   Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n",
       " 0        NaN        NaN        NaN        NaN  \n",
       " 1        NaN        NaN        NaN        NaN  \n",
       " 2        NaN        NaN        NaN        NaN  \n",
       " 3        NaN        NaN        NaN        NaN  \n",
       " 4        NaN        NaN        NaN        NaN  )"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/isear/isear-train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe and its info to understand the structure and contents\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "data_info, data_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1472b2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5334 entries, 0 to 5340\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Emotion Label  5334 non-null   object\n",
      " 1   Text           5334 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 125.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  Emotion Label                                               Text\n",
       " 0           joy  When I understood that I was admitted to the U...\n",
       " 1          fear  I broke a window of a neighbouring house and I...\n",
       " 2           joy                         Got a big fish in fishing.\n",
       " 3          fear  Whenever I am alone in a dark room, walk alone...\n",
       " 4         shame  I bought a possible answer to a homework probl...,\n",
       " None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the dataset by dropping unnecessary columns and any missing values in the main columns of interest\n",
    "cleaned_data = data[['Emotion Label', 'Text']].dropna()\n",
    "\n",
    "# Check the cleaned data structure\n",
    "cleaned_data.head(), cleaned_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb703cad",
   "metadata": {},
   "source": [
    "It seems there are some entries in the \"Emotion Label\" column with incorrect formatting or additional text. I'll correct these entries and provide a cleaned-up distribution of emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a7a113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion Label\n",
       "joy        778\n",
       "guilt      769\n",
       "sadness    762\n",
       "shame      758\n",
       "disgust    758\n",
       "anger      758\n",
       "fear       751\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the improperly formatted emotion labels by extracting only the relevant emotion part\n",
    "cleaned_data['Emotion Label'] = cleaned_data['Emotion Label'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Recalculate the distribution of emotions after cleaning\n",
    "cleaned_emotion_distribution = cleaned_data['Emotion Label'].value_counts()\n",
    "\n",
    "# Display the cleaned distribution of emotions\n",
    "cleaned_emotion_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58539945",
   "metadata": {},
   "source": [
    "The emotions are quite evenly distributed across the dataset. This distribution can be visualized in a bar chart if you'd like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd8b7f",
   "metadata": {},
   "source": [
    "second insight, which is the analysis of the average length of text entries for each emotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b2744f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion Label\n",
       "anger      127.112137\n",
       "disgust    110.885224\n",
       "fear       117.944075\n",
       "guilt      118.661899\n",
       "joy         98.410026\n",
       "sadness    103.771654\n",
       "shame      111.841689\n",
       "Name: Text Length, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average length of text entries for each emotion\n",
    "cleaned_data['Text Length'] = cleaned_data['Text'].apply(len)\n",
    "average_text_length_by_emotion = cleaned_data.groupby('Emotion Label')['Text Length'].mean()\n",
    "\n",
    "# Display the average text length for each emotion\n",
    "average_text_length_by_emotion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15e4ef",
   "metadata": {},
   "source": [
    "analyze the most common words used across the dataset and within each emotion category to identify key themes and expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50a1f8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 7625, 'my': 3255, 'was': 3159, 'when': 2556, 'had': 1805, 'me': 1593, 'not': 1152, 'with': 1059, 'it': 1034, 'at': 1024, 'he': 694, 'friend': 686, 'very': 680, 'felt': 628, 'an': 542, 'she': 527, 'her': 517, 'we': 491, 'about': 486, 'one': 480}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def simple_count_vectorizer(texts, top_n=20, stopwords=None):\n",
    "    \n",
    "    if stopwords is None:\n",
    "        stopwords = set()  # Define or import a list of stopwords if necessary\n",
    "    \n",
    "    # Initialize a counter to hold all word counts\n",
    "    word_count = Counter()\n",
    "\n",
    "    # Process each document\n",
    "    for text in texts:\n",
    "        # Tokenize and clean text\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())  # Tokenize and convert to lower case\n",
    "        # Remove stopwords and count words\n",
    "        filtered_words = [word for word in words if word not in stopwords]\n",
    "        word_count.update(filtered_words)\n",
    "    \n",
    "    # Get the most common words\n",
    "    most_common_words = dict(word_count.most_common(top_n))\n",
    "    \n",
    "    return most_common_words\n",
    "\n",
    "# Example usage:\n",
    "texts = cleaned_data['Text'].tolist()\n",
    "stopwords = set(['the', 'and', 'to', 'of', 'a', 'in', 'that', 'is', 'on', 'for'])  # Define more if needed\n",
    "top_words = simple_count_vectorizer(texts, top_n=20, stopwords=stopwords)\n",
    "\n",
    "print(top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25eb635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
